{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom multimodal dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os \n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "\n",
    "\n",
    "image_dir = r'\\Users\\jqvil\\Desktop\\jessica quenneville\\images\\images'\n",
    "csv_file = 'UTKFaceAugmented.csv'\n",
    "\n",
    "data = pd.read_csv(csv_file)\n",
    "# Placeholder to store image data and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "# Load and preprocess images\n",
    "for index, row in data.iterrows():\n",
    "    filename = row['filename']  \n",
    "    age_label = row['age']  \n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    if os.path.exists(image_path):  # Check if the file exists before processing\n",
    "        img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "        img = img.resize((64, 64))\n",
    "        img_tensor = torch.tensor(np.array(img) / 255.0, dtype=torch.float32)\n",
    "        images.append(img_tensor.unsqueeze(0))  # Add a batch dimension\n",
    "        labels.append(age_label)\n",
    "    else:\n",
    "        print(f\"File not found: {image_path}\")\n",
    "\n",
    "\n",
    "image_tensor = torch.cat(images, dim=0)\n",
    "labels = torch.tensor(labels, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate output shape after convolution\n",
    "def calculate_output_shape(image_size, kernel, stride, padding):\n",
    "    assert len(image_size) == len(kernel) == len(stride) == len(padding), \"All values should have the same length\"\n",
    "    output_shape = []\n",
    "    for dim in range(len(image_size)):\n",
    "        output = 1 + (image_size[dim] + (2 * padding[dim]) - kernel[dim]) / stride[dim]\n",
    "        assert output.is_integer(), \"Change kernel size, padding, and stride to get an integer value for the output\"\n",
    "        output_shape.append(int(output))\n",
    "    return output_shape\n",
    "\n",
    "# Calculate output shape after convolution\n",
    "output_shape = calculate_output_shape([8, 8], [3, 3], [3, 3], [2, 2])\n",
    "print(\"Output Shape after Convolution:\", output_shape)\n",
    "\n",
    "# Create a convolutional layer with adjusted kernel size\n",
    "conv = nn.Conv2d(\n",
    "    in_channels=3,  # 3 channels RGB\n",
    "    out_channels=64,  # Number of kernels to train\n",
    "    kernel_size=(3, 3),  # Adjusted kernel size to demonstrate convolution\n",
    "    stride=(1, 1),\n",
    "    padding=(2, 2)\n",
    ")\n",
    "\n",
    "# Create a random input image (8x8x1)\n",
    "image_np = np.random.randn(3, 3, 8, 8).astype(np.float32)\n",
    "image_tensor = torch.from_numpy(image_np)\n",
    "output = conv(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract indices where target equals 8\n",
    "indices = (image_tensor == 1).nonzero(as_tuple=True)\n",
    "\n",
    "# Use the extracted indices to get corresponding data and target values\n",
    "x = image_tensor[indices[:20]]\n",
    "y = image_tensor[indices[:20]]\n",
    "print(x,y)\n",
    "\n",
    "\n",
    "\n",
    "# prep the data for training\n",
    "x = np.reshape(x, (len(x), 8, 1, 1))\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# prep the data for training\n",
    "x = np.reshape(x, (len(x), 8, 1, 1))\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "conv_1kernel = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=(20,20),\n",
    "    stride=(1, 1),\n",
    "    padding=(1, 1)  \n",
    ")\n",
    "\n",
    "\n",
    "# lets set up a training loop, and save snapshots of each kernel every epoch\n",
    "optimizer = torch.optim.Adam(conv_1kernel.parameters(), lr = 0.001)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction = 'none')\n",
    "# Initialize the list to store learned kernels\n",
    "kernels = []\n",
    "\n",
    "# Append the initial kernel \n",
    "kernels.append(conv_1kernel.weight.data.detach().numpy().copy())\n",
    "\n",
    "optimizer = torch.optim.Adam(conv_1kernel.parameters(), lr = 0.001)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction = 'none')\n",
    "\n",
    "\n",
    "kernels.append([param.detach().numpy().copy() for param in conv_1kernel.parameters()][0])\n",
    "for _ in range(10):\n",
    "    for i in range(len(x)):\n",
    "        optimizer.zero_grad()\n",
    "        yhat = torch.squeeze(conv_1kernel(x[i:i+1]))\n",
    "        loss = loss_fn(y[i], yhat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    kernels.append([param.detach().numpy().copy() for param in conv_1kernel.parameters()][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can fetch an item from the data like so, which gives us the image in PIL form, and the class label as an int\n",
    "image_data_list = []\n",
    "count = 0\n",
    "\n",
    "# Loop through image files in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    # Check if the file is an image (ends with .jpg)\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # Construct the full path to the image file\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        # Open the image using PIL\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Convert the image to a NumPy array and append to the list\n",
    "        img_array = np.array(img)\n",
    "        image_data_list.append(img_array)\n",
    "        # Increment count\n",
    "        count += 1\n",
    "        \n",
    "        # Break the loop when 1000 images are read\n",
    "        if count >= 20:\n",
    "            break\n",
    "\n",
    "\n",
    "# Convert the list of image arrays to a NumPy array\n",
    "image_data = np.array(image_data_list, dtype=np.float32)\n",
    "\n",
    "num_rows = 4  # 20 images in 4 rows\n",
    "num_cols = 5  # 5 images per row\n",
    "\n",
    "# Create a subplot grid to display multiple images\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(50, 50))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display the first 1000 images in a grid format\n",
    "\n",
    "image_data_normalized = image_data / 255.0 \n",
    "for i in range(20):\n",
    "    axes[i].imshow(image_data_normalized[i], cmap='viridis')  #  colormap viridis\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import CNNClassifier\n",
    "from dataloader import CustomImageDataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(image_data, labels[:20], test_size=0.2, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.stack([torch.tensor(np.array(img), dtype=torch.float32) for img in x_train])\n",
    "x_val = torch.stack([torch.tensor(np.array(img), dtype=torch.float32) for img in x_val])\n",
    "x_test = torch.stack([torch.tensor(np.array(img), dtype=torch.float32) for img in x_test])\n",
    "\n",
    "num_classes = 32\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = np.clip(y_train, 0, num_classes - 1)\n",
    "y_val = np.clip(y_val, 0, num_classes - 1)\n",
    "y_test = np.clip(y_test, 0, num_classes - 1)\n",
    "\n",
    "# One-hot encode the labels for training, validation, and test sets\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "y_train = torch.nn.functional.one_hot(y_train, num_classes=num_classes)\n",
    "\n",
    "y_val = torch.tensor(y_val, dtype=torch.int64)\n",
    "y_val = torch.nn.functional.one_hot(y_val, num_classes=num_classes)\n",
    "\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "y_test = torch.nn.functional.one_hot(y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(image_data[:20])):\n",
    "    img = image_data[i]\n",
    "    label = []\n",
    "    x.append(torch.tensor(np.array(img), dtype=torch.float32))\n",
    "    y.append(label)\n",
    "# Validation Data\n",
    "x = []\n",
    "y = []\n",
    "for img_tensor in x_train:\n",
    "    x.append(torch.tensor(np.array(img_tensor), dtype=torch.float32))\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    img = image_data[i]\n",
    "    label = []\n",
    "    x.append(torch.tensor(np.array(img), dtype=torch.float32))\n",
    "    y.append(label)\n",
    "# Stack x to create x_val tensor\n",
    "x_val = torch.stack(x)\n",
    "x_val = torch.unsqueeze(x_val, 1)  # Reshape x_val if needed\n",
    "\n",
    "# One-hot encode the labels y into y_val tensor\n",
    "num_classes = 10 \n",
    "y_val = torch.zeros(len(y), num_classes)\n",
    "y_indices = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Initialize y_val with appropriate dimensions\n",
    "y_val = torch.zeros(len(y), num_classes)\n",
    "\n",
    "# Assign 1s to specific positions\n",
    "x_val = torch.stack(x)\n",
    "x_val = torch.unsqueeze(x_val, 1)\n",
    "y_val = torch.zeros(len(y),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = CustomImageDataloader(x = x_train, y = y_train, batch_size=16, randomize=True)\n",
    "val_dataloader = CustomImageDataloader(x = x_val, y = y_val, batch_size=16, randomize=False)\n",
    "\n",
    "model = CNNClassifier(32)\n",
    "\n",
    "\n",
    "\n",
    "# instantiate your optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# log your losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# define how many epochs to train on\n",
    "epochs = 50\n",
    "\n",
    "# define your loss function for multiclass classification task\n",
    "# BCE does binary cross entropy automatically for each class\n",
    "loss_fn = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "for _ in tqdm.tqdm(range(epochs)):\n",
    "    losses = []\n",
    "    for _ in range(train_dataloader.num_batches_per_epoch):\n",
    "        # training data forward pass\n",
    "        optimizer.zero_grad()\n",
    "        train_batch = train_dataloader.fetch_batch()\n",
    "        yhat = model(train_batch['x_batch'])\n",
    "        train_loss = torch.mean(loss_fn(yhat.float(), train_batch['y_batch'].float()))\n",
    "\n",
    "        # training data backward pass\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(train_loss.detach().numpy())\n",
    "\n",
    "    # personally, I like to visualize the loss per every iteration, rather than every epoch. I find it more useful to diagnose issues\n",
    "    train_losses.extend(losses)\n",
    "    \n",
    "    losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_age(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predicted_ages = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(dataloader.num_batches_per_epoch):\n",
    "            val_batch = dataloader.fetch_batch()\n",
    "            yhat = model(val_batch['x_batch'])\n",
    "            predicted_ages.extend(yhat.cpu().numpy()) \n",
    "    \n",
    "    return predicted_ages\n",
    "\n",
    "# Use the trained model and validation dataloader to predict ages\n",
    "predicted_ages = predict_age(model, train_dataloader)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a histogram of predicted ages\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(predicted_ages, bins=30, edgecolor='black')\n",
    "plt.xlabel('Predicted Ages')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Predicted Ages')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting training loss per epoch\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss', marker='o', color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting Training Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_losses, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Training Loss Distribution')\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Frequency')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
